


pip install locust






locust \--version






from locust import HttpUser, task, between  
 import random  
 import json  
 import time  
 import os

 class ReasoningAgentUser(HttpUser):  
 	"""  
 	Simulates a user interacting with DeepSeek reasoning agents.  
 	This class defines realistic behavior patterns and query types.  
 	"""  
 	  
 	\# Wait between 2-8 seconds between requests (realistic user behavior)  
 	wait\_time \= between(2, 8\)  
 	  
 	def on\_start(self):  
     	"""  
     	Initialize each simulated user with API credentials and query sets.  
     	This runs once when each simulated user starts.  
     	"""  
     	  
     	\# Set up authentication headers  
     	\# Replace 'your\_actual\_api\_key' with your real DeepSeek API key  
     	self.api\_key \= os.getenv("DEEPSEEK\_API\_KEY") or "your\_actual\_api\_key"  
     	self.headers \= {  
         	"Content-Type": "application/json",  
         	"Authorization": f"Bearer {self.api\_key}"  
     	}  
     	  
     	\# Define different categories of queries to test various scenarios  
     	self.simple\_queries \= \[  
         	"What is 2+2?",  
         	"Define machine learning in one sentence.",  
         	"What is the capital of France?",  
         	"Convert 100 fahrenheit to celsius.",  
         	"What does API stand for?",  
         	"Name three primary colors.",  
         	"What is Python programming language?",  
         	"How many seconds in an hour?"  
     	\]  
     	  
     	self.medium\_queries \= \[  
         	"Explain the difference between machine learning and deep learning.",  
         	"What are the advantages and disadvantages of remote work?",  
         	"How does photosynthesis work?",  
         	"Describe the water cycle.",  
         	"What are the main causes of climate change?",  
         	"Explain how a computer processes information.",  
         	"What is the difference between SQL and NoSQL databases?",  
         	"How do search engines rank web pages?"  
     	\]  
     	  
     	self.complex\_queries \= \[  
         	"Analyze the trade-offs between different sorting algorithms and explain when to use each one.",  
         	"Design a system architecture for a real-time data processing platform that handles millions of events per second.",  
         	"Compare and contrast democratic and authoritarian governance systems, considering historical examples and modern implications.",  
         	"Explain the economic implications of artificial intelligence on employment, including both positive and negative effects with supporting evidence.",  
         	"Analyze the ethical considerations in genetic engineering, including benefits, risks, and regulatory frameworks.",  
         	"Design a comprehensive marketing strategy for a new sustainable energy product, including target audience analysis and competitive positioning."  
     	\]  
     	  
     	self.reasoning\_intensive\_queries \= \[  
         	"If a train leaves Station A at 2:00 PM traveling at 60 mph, and another train leaves Station B (120 miles away) at 2:30 PM traveling at 80 mph toward Station A, at what time and location will they meet? Show your reasoning step by step.",  
         	"A company's revenue was $100,000 in January. It increased by 15% in February, decreased by 8% in March, and increased by 22% in April. What was the revenue in April, and what was the overall percentage change from January to April? Explain your calculations.",  
         	"You have a 3-gallon jug and a 5-gallon jug. How can you measure exactly 4 gallons of water? Provide step-by-step reasoning for your solution.",  
         	"Three friends split a restaurant bill. Alice paid $30, Bob paid $25, and Charlie paid $20. They want to split it equally. Who owes money to whom, and how much? Show your reasoning process."  
     	\]  
     	  
     	\# Track this user's session for analytics  
     	self.user\_session\_id \= f"user\_{random.randint(10000, 99999)}\_{int(time.time())}"  
     	print(f"üéØ Started load test user: {self.user\_session\_id}")  
 	  
 	def make\_reasoning\_request(self, query: str, max\_tokens: int \= 1000, reasoning\_steps: bool \= True):  
     	"""  
     	Make a request to the DeepSeek API with proper error handling and metrics collection.  
     	"""  
     	  
     	payload \= {  
         	"model": "deepseek-reasoner",  
         	"messages": \[{"role": "user", "content": query}\],  
         	"max\_tokens": max\_tokens,  
         	"temperature": 0.1,  
         	"reasoning\_steps": reasoning\_steps  
     	}  
     	  
     	\# Record request details for debugging  
     	request\_start \= time.time()  
     	  
     	try:  
         	\# Make the API call  
         	with self.client.post(  
                 "/v1/chat/completions",  
             	json=payload,  
             	headers=self.headers,  
             	catch\_response=True,  
             	timeout=30  \# 30 second timeout  
         	) as response:  
             	  
             	request\_time \= time.time() \- request\_start  
     	          
             	if response.status\_code \== 200:  
                 	\# Parse response to get token usage  
                 	try:  
                     	response\_data \= response.json()  
                     	tokens\_used \= response\_data.get('usage', {}).get('total\_tokens', 0\)  
                     	  
                     	\# Log successful request details  
                     	print(f"‚úÖ Query processed in {request\_time:.2f}s, {tokens\_used} tokens: {query\[:50\]}...")  
                     	  
                     	\# Mark as success in Locust  
                         response.success()  
                     	  
                 	except json.JSONDecodeError:  
                     	print(f"‚ùå Invalid JSON response for query: {query\[:50\]}...")  
                         response.failure("Invalid JSON response")  
                     	  
             	elif response.status\_code \== 429:  
                 	\# Rate limiting \- this is expected under high load  
                 	print(f"‚ö†Ô∏è Rate limited for query: {query\[:50\]}...")  
                     response.failure("Rate limited")  
                 	  
             	elif response.status\_code \== 401:  
                 	print(f"‚ùå Authentication failed \- check API key")  
                     response.failure("Authentication failed")  
                 	  
             	else:  
                 	print(f"‚ùå Request failed with status {response.status\_code}: {query\[:50\]}...")  
                     response.failure(f"HTTP {response.status\_code}")  
                 	  
     	except Exception as e:  
         	print(f"‚ùå Request exception: {str(e)\[:100\]}...")  
         	\# Don't re-raise \- let Locust handle the failure  
 	  
 	@task(50)  \# 50% of requests are simple queries  
 	def simple\_reasoning\_task(self):  
     	"""  
     	Test simple queries that should respond quickly.  
     	These represent basic user questions and quick lookups.  
     	"""  
     	  
     	query \= random.choice(self.simple\_queries)  
     	print(f"üîπ Simple task: {query\[:30\]}...")  
     	  
     	self.make\_reasoning\_request(  
         	query=query,  
         	max\_tokens=500,  
         	reasoning\_steps=False  \# Simple queries don't need reasoning steps  
     	)  
 	  
 	@task(30)  \# 30% are medium complexity queries  
 	def medium\_reasoning\_task(self):  
     	"""  
     	Test medium complexity queries that require some explanation.  
     	These represent typical user questions requiring detailed responses.  
     	"""  
     	  
     	query \= random.choice(self.medium\_queries)  
     	print(f"üî∏ Medium task: {query\[:30\]}...")  
     	  
     	self.make\_reasoning\_request(  
         	query=query,  
         	max\_tokens=1200,  
         	reasoning\_steps=True  \# Show some reasoning for medium queries  
     	)  
 	  
 	@task(15)  \# 15% are complex analytical queries  
 	def complex\_reasoning\_task(self):  
     	"""  
     	Test complex queries that require detailed analysis and reasoning.  
     	These represent power users asking sophisticated questions.  
     	"""  
     	  
     	query \= random.choice(self.complex\_queries)  
     	print(f"üî∂ Complex task: {query\[:30\]}...")  
     	  
     	self.make\_reasoning\_request(  
         	query=query,  
         	max\_tokens=2500,  
         	reasoning\_steps=True  \# Full reasoning for complex queries  
     	)  
 	  
 	@task(5)  \# 5% are reasoning-intensive mathematical/logical problems  
 	def intensive\_reasoning\_task(self):  
     	"""  
     	Test the most demanding reasoning tasks.  
     	These represent users asking for step-by-step problem solving.  
     	"""  
     	  
     	query \= random.choice(self.reasoning\_intensive\_queries)  
     	print(f"üî¥ Intensive task: {query\[:30\]}...")  
     	  
     	self.make\_reasoning\_request(  
         	query=query,  
         	max\_tokens=3000,  
         	reasoning\_steps=True  \# Maximum reasoning for intensive tasks  
     	)

 class QuickTestUser(HttpUser):  
 	"""  
 	A simpler user class for quick load tests and debugging.  
 	Use this when you want to test basic functionality without complex scenarios.  
 	"""  
 	  
 	wait\_time \= between(1, 3\)  \# Faster requests for quick testing  
 	  
 	def on\_start(self):  
         self.api\_key \= os.getenv("DEEPSEEK\_API\_KEY") or "your\_actual\_api\_key"  
     	self.headers \= {  
         	"Content-Type": "application/json",  
         	"Authorization": f"Bearer {self.api\_key}"  
     	}  
 	  
 	@task  
 	def quick\_test(self):  
     	"""Simple test query for debugging and quick validation."""  
     	  
     	payload \= {  
         	"model": "deepseek-reasoner",  
         	"messages": \[{"role": "user", "content": "What is 5 \+ 3?"}\],  
         	"max\_tokens": 100,  
         	"temperature": 0.1  
     	}  
     	  
         self.client.post("/v1/chat/completions", json=payload, headers=self.headers)






locust \-f locustfile.py \--host=https://api.deepseek.com \--users=5 \--spawn-rate=1 \--run-time=2m \--headless



Let's break down what each parameter does:

¬∑       \-f locustfile.py: Specifies your test file

¬∑       \--host=https://api.deepseek.com: The base URL for your API calls

¬∑       \--users=5: Start with 5 simulated concurrent users

¬∑       \--spawn-rate=1: Add 1 new user per second until reaching the target

¬∑       \--run-time=2m: Run the test for 2 minutes

¬∑       \--headless: Run without the web interface (results printed to console)

You should see output like this in your terminal:

\[2025-08-08 15:16:12,345\] Starting Locust 2.x.x  
 \[2025-08-08 15:16:12,346\] Spawning 5 users at the rate 1 users/s (0 users already running)...  
 ‚úÖ Query processed in 1.23s, 45 tokens: What is 2+2?...  
 üîπ Simple task: What is the capital of France...  
 ‚úÖ Query processed in 0.89s, 32 tokens: What is the capital of France...

**Interactive Load Testing with Web Interface**

For more detailed monitoring and real-time control, run Locust with its web interface:



locust \-f locustfile.py \--host=https://api.deepseek.com






\# Step 1: Minimal load (verify functionality)  
 locust \-f locustfile.py \--host=https://api.deepseek.com \--users=2 \--spawn-rate=1 \--run-time=1m \--headless

 \# Step 2: Light load (baseline performance)  
 locust \-f locustfile.py \--host=https://api.deepseek.com \--users=10 \--spawn-rate=2 \--run-time=3m \--headless

 \# Step 3: Moderate load (typical usage)  
 locust \-f locustfile.py \--host=https://api.deepseek.com \--users=25 \--spawn-rate=5 \--run-time=5m \--headless

 \# Step 4: Heavy load (peak traffic simulation)  
 locust \-f locustfile.py \--host=https://api.deepseek.com \--users=50 \--spawn-rate=5 \--run-time=10m \--headless

 \# Step 5: Stress test (find breaking point)  
 locust \-f locustfile.py \--host=https://api.deepseek.com \--users=100 \--spawn-rate=10 \--run-time=10m \--headless





class RealisticSessionUser(HttpUser):  
 	"""  
 	Simulates realistic user sessions with multiple related queries.  
 	Models how real users might have conversations or work sessions with the AI.  
 	"""  
 	  
 	wait\_time \= between(3, 15\)  \# More realistic thinking time between queries  
 	  
 	def on\_start(self):  
     	"""Initialize user with session-based behavior patterns."""  
     	  
     	self.api\_key \= os.getenv("DEEPSEEK\_API\_KEY") or "your\_actual\_api\_key"  
     	self.headers \= {  
         	"Content-Type": "application/json",  
         	"Authorization": f"Bearer {self.api\_key}"  
     	}  
     	  
     	\# Define conversation themes that users might explore  
     	self.conversation\_themes \= {  
         	"programming": \[  
             	"What is Python programming language?",  
             	"How do I write a function in Python?",  
             	"What are the best practices for Python code?",  
             	"Explain object-oriented programming in Python.",  
             	"How do I handle errors in Python?"  
         	\],  
             "business\_analysis": \[  
             	"What is market research?",  
             	"How do I analyze competitor strategies?",  
             	"What are key performance indicators for business?",  
             	"Explain different pricing strategies.",  
             	"How do I create a business plan?"  
         	\],  
         	"science": \[  
             	"What is quantum physics?",  
             	"Explain the theory of relativity.",  
             	"How do black holes work?",  
             	"What is the difference between DNA and RNA?",  
             	"Explain photosynthesis in detail."  
         	\]  
     	}  
     	  
     	\# Each user picks a theme for their session  
     	self.current\_theme \= random.choice(list(self.conversation\_themes.keys()))  
     	self.theme\_queries \= self.conversation\_themes\[self.current\_theme\].copy()  
         random.shuffle(self.theme\_queries)  \# Randomize order  
     	  
     	self.session\_query\_count \= 0  
     	self.max\_session\_queries \= random.randint(3, 7\)  \# 3-7 queries per session  
     	  
     	print(f"üë§ User session started with theme: {self.current\_theme}")  
 	  
 	@task  
 	def themed\_conversation(self):  
     	"""  
     	Simulate a user having a themed conversation with the AI.  
     	"""  
     	  
     	if self.session\_query\_count \>= self.max\_session\_queries:  
         	\# End this user's session  
         	print(f"üë§ User session completed ({self.session\_query\_count} queries)")  
         	self.stop()  
         	return  
     	  
     	if self.theme\_queries:  
         	query \= self.theme\_queries.pop(0)  
     	else:  
         	\# If we run out of themed queries, ask follow-up questions  
         	query \= f"Can you elaborate more on the previous topic?"  
     	  
     	self.session\_query\_count \+= 1  
     	  
     	print(f"üó£Ô∏è Session query {self.session\_query\_count}: {query\[:40\]}...")  
     	  
     	\# Adjust parameters based on session progress  
     	\# Later queries in a session tend to be more specific/complex  
     	max\_tokens \= 800 \+ (self.session\_query\_count \* 200\)  \# Gradually increase depth  
     	reasoning\_steps \= self.session\_query\_count \> 1  \# Enable reasoning after first query  
     	  
         self.make\_reasoning\_request(query, max\_tokens, reasoning\_steps)  
 	  
 	def make\_reasoning\_request(self, query: str, max\_tokens: int \= 1000, reasoning\_steps: bool \= True):  
     	"""Make API request with session tracking."""  
     	  
     	payload \= {  
         	"model": "deepseek-reasoner",  
         	"messages": \[{"role": "user", "content": query}\],  
         	"max\_tokens": max\_tokens,  
         	"temperature": 0.1,  
         	"reasoning\_steps": reasoning\_steps  
     	}  
     	  
     	with self.client.post(  
             "/v1/chat/completions",  
         	json=payload,  
         	headers=self.headers,  
      	   catch\_response=True,  
         	timeout=45  \# Longer timeout for session-based queries  
     	) as response:  
         	  
         	if response.status\_code \== 200:  
             	try:  
                 	response\_data \= response.json()  
                 	tokens\_used \= response\_data.get('usage', {}).get('total\_tokens', 0\)  
                 	print(f"‚úÖ Session query completed: {tokens\_used} tokens")  
                 	response.success()  
             	except json.JSONDecodeError:  
                     response.failure("Invalid JSON response")  
         	else:  
             	print(f"‚ùå Session query failed: {response.status\_code}")  
                 response.failure(f"HTTP {response.status\_code}")






class TimeBasedUser(HttpUser):  
 	"""  
 	Simulates users with different behavior patterns based on time of day.  
 	Morning users might ask different types of questions than evening users.  
 	"""  
 	  
 	def on\_start(self):  
     	self.api\_key \= os.getenv("DEEPSEEK\_API\_KEY") or "your\_actual\_api\_key"  
     	self.headers \= {  
         	"Content-Type": "application/json",  
         	"Authorization": f"Bearer {self.api\_key}"  
     	}  
     	  
     	\# Determine user type based on simulated time of day  
     	hour \= random.randint(6, 23\)  \# Simulate 6 AM to 11 PM  
     	  
     	if 6 \<= hour \<= 9:  \# Morning users  
         	self.user\_type \= "morning\_commuter"  
         	self.wait\_time \= between(1, 3\)  \# Quick queries  
         	self.query\_pool \= \[  
             	"What's the weather like today?",  
             	"Give me a quick summary of today's news.",  
             	"What's my schedule optimization tip for today?"  
         	\]  
     	elif 9 \<= hour \<= 17:  \# Business hours  
         	self.user\_type \= "business\_user"  
         	self.wait\_time \= between(5, 20\)  \# Thoughtful queries  
         	self.query\_pool \= \[  
             	"Analyze this business proposal for potential risks.",  
             	"What are the latest trends in digital marketing?",  
             	"Help me write a professional email response."  
         	\]  
     	else:  \# Evening users  
         	self.user\_type \= "evening\_learner"  
         	self.wait\_time \= between(10, 30\)  \# Deep learning sessions  
         	self.query\_pool \= \[  
             	"Explain quantum computing in detail.",  
             	"What are the philosophical implications of AI?",  
             	"Help me understand complex mathematical concepts."  
         	\]  
     	  
     	print(f"üïê {self.user\_type} user active (simulated hour: {hour})")  
 	  
 	@task  
 	def time\_appropriate\_query(self):  
     	"""Make queries appropriate for the user's time-based profile."""  
     	  
     	query \= random.choice(self.query\_pool)  
     	  
     	\# Adjust request parameters based on user type  
     	if self.user\_type \== "morning\_commuter":  
         	max\_tokens \= 300  \# Brief responses  
         	reasoning\_steps \= False  
     	elif self.user\_type \== "business\_user":  
         	max\_tokens \= 1500  \# Professional depth  
         	reasoning\_steps \= True  
     	else:  \# evening\_learner  
         	max\_tokens \= 2500  \# Deep explanations  
         	reasoning\_steps \= True  
     	  
         self.make\_reasoning\_request(query, max\_tokens, reasoning\_steps)  
 	  
 	def make\_reasoning\_request(self, query: str, max\_tokens: int, reasoning\_steps: bool):  
     	"""Make request with user-type specific handling."""  
     	  
     	payload \= {  
         	"model": "deepseek-reasoner",  
         	"messages": \[{"role": "user", "content": query}\],  
         	"max\_tokens": max\_tokens,  
         	"temperature": 0.1,  
         	"reasoning\_steps": reasoning\_steps  
     	}  
     	  
         self.client.post("/v1/chat/completions", json=payload, headers=self.headers)






import csv  
 from datetime import datetime

 class LoadTestReporter:  
 	"""  
 	Custom reporter for analyzing and documenting load test results.  
 	"""  
 	  
 	def \_\_init\_\_(self):  
     	self.test\_results \= \[\]  
 	  
 	def record\_test\_run(self, test\_name: str, users: int, duration: int,  
                    	avg\_response\_time: float, failure\_rate: float,  
                    	rps: float, notes: str \= ""):  
     	"""Record the results of a load test run."""  
     	  
     	result \= {  
         	'timestamp': datetime.now().isoformat(),  
         	'test\_name': test\_name,  
         	'concurrent\_users': users,  
         	'duration\_minutes': duration,  
         	'avg\_response\_time': avg\_response\_time,  
         	'failure\_rate\_percent': failure\_rate,  
         	'requests\_per\_second': rps,  
         	'notes': notes  
     	}  
     	  
     	self.test\_results.append(result)  
     	print(f"üìä Recorded test result: {test\_name} with {users} users")  
 	  
 	def generate\_performance\_report(self, filename: str \= None):  
     	"""Generate a comprehensive performance report."""  
     	  
     	if not filename:  
         	timestamp \= datetime.now().strftime("%Y%m%d\_%H%M%S")  
         	filename \= f"load\_test\_report\_{timestamp}.csv"  
     	  
     	with open(filename, 'w', newline='') as csvfile:  
         	fieldnames \= \[  
             	'timestamp', 'test\_name', 'concurrent\_users', 'duration\_minutes',  
             	'avg\_response\_time', 'failure\_rate\_percent', 'requests\_per\_second', 'notes'  
         	\]  
         	  
         	writer \= csv.DictWriter(csvfile, fieldnames=fieldnames)  
         	writer.writeheader()  
         	  
         	for result in self.test\_results:  
             	writer.writerow(result)  
     	  
     	print(f"üìà Performance report saved to: {filename}")  
     	  
     	\# Generate summary statistics  
     	if self.test\_results:  
         	total\_tests \= len(self.test\_results)  
         	avg\_response\_time \= sum(r\['avg\_response\_time'\] for r in self.test\_results) / total\_tests  
         	max\_users\_tested \= max(r\['concurrent\_users'\] for r in self.test\_results)  
         	avg\_failure\_rate \= sum(r\['failure\_rate\_percent'\] for r in self.test\_results) / total\_tests  
         	  
         	print(f"\\nüìä LOAD TEST SUMMARY")  
         	print(f"Total test runs: {total\_tests}")  
         	print(f"Maximum concurrent users tested: {max\_users\_tested}")  
         	print(f"Average response time across all tests: {avg\_response\_time:.2f}s")  
         	print(f"Average failure rate: {avg\_failure\_rate:.2f}%")  
 	  
 	def recommend\_production\_settings(self):  
     	"""Analyze results and recommend production settings."""  
     	  
     	if not self.test\_results:  
         	print("‚ùå No test results available for analysis")  
         	return  
     	  
     	\# Find the highest load test with acceptable performance  
     	acceptable\_tests \= \[  
         	r for r in self.test\_results  
         	if r\['failure\_rate\_percent'\] \<= 5.0 and r\['avg\_response\_time'\] \<= 10.0  
     	\]  
     	  
     	if acceptable\_tests:  
         	best\_test \= max(acceptable\_tests, key=lambda x: x\['concurrent\_users'\])  
         	  
         	print(f"\\nüí° PRODUCTION RECOMMENDATIONS")  
         	print(f"Recommended max concurrent users: {best\_test\['concurrent\_users'\]}")  
         	print(f"Expected average response time: {best\_test\['avg\_response\_time'\]:.2f}s")  
         	print(f"Expected failure rate: {best\_test\['failure\_rate\_percent'\]:.2f}%")  
         	print(f"Expected throughput: {best\_test\['requests\_per\_second'\]:.1f} RPS")  
         	  
         	\# Calculate cost estimates  
         	daily\_requests \= best\_test\['requests\_per\_second'\] \* 86400  \# Requests per day  
         	print(f"\\nEstimated daily request volume: {daily\_requests:,.0f} requests")  
         	  
     	else:  
         	print("‚ö†Ô∏è No test runs met acceptable performance criteria")  
         	print("Consider optimizing your system before production deployment")

 \# Example usage in your load testing workflow  
 reporter \= LoadTestReporter()

 \# After each test run, record the results  
 \# reporter.record\_test\_run("Light Load", 10, 3, 1.5, 0.2, 15.3, "Baseline test")  
 \# reporter.record\_test\_run("Heavy Load", 50, 10, 3.2, 2.1, 45.7, "Peak traffic simulation")

 \# Generate final report  
 \# reporter.generate\_performance\_report()  
 \# reporter.recommend\_production\_settings()






def calculate\_production\_costs(daily\_requests: int, avg\_tokens\_per\_request: int,  
                               token\_cost\_per\_1000: float \= 0.002):  
 	"""  
 	Calculate estimated production costs based on load testing data.  
 	"""  
 	  
 	daily\_tokens \= daily\_requests \* avg\_tokens\_per\_request  
 	daily\_cost \= (daily\_tokens / 1000\) \* token\_cost\_per\_1000  
 	monthly\_cost \= daily\_cost \* 30  
 	  
 	print(f"üí∞ PRODUCTION COST ESTIMATES")  
 	print(f"Daily requests: {daily\_requests:,}")  
 	print(f"Daily tokens: {daily\_tokens:,}")  
 	print(f"Daily cost: ${daily\_cost:.2f}")  
 	print(f"Monthly cost: ${monthly\_cost:.2f}")  
 	print(f"Annual cost: ${monthly\_cost \* 12:.2f}")  
 	  
 	return {  
     	'daily\_cost': daily\_cost,  
     	'monthly\_cost': monthly\_cost,  
     	'annual\_cost': monthly\_cost \* 12  
 	}

 \# Example calculation based on load test results  
 \# costs \= calculate\_production\_costs(  
 \# 	daily\_requests=10000,  
 \# 	avg\_tokens\_per\_request=500,  
 \# 	token\_cost\_per\_1000=0.002  
 \# )




